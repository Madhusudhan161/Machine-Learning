{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c345eb-f8ff-4081-9d10-cb57d23df1bc",
   "metadata": {},
   "source": [
    "### 1 . What is the filter method in feature selection and how does it work ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a18bb-2f31-44b6-99b4-60407ba79e8a",
   "metadata": {},
   "source": [
    "##### Filter Method :\n",
    "- The filter method in feature selection is a technique used to select most relevant features from a dataset based on certain statistical measures or criteria. it involves evaluating each feature independently of the others and ranking them according to thier relevance to the target variable. the filter method doesn't involve bilding a model. it relies on statistical properties of data.\n",
    "\n",
    "##### The filter works by evaluating each feature :\n",
    "1. Calculating the relevance feature \n",
    "2. Rank Features \n",
    "3. Select Top Features\n",
    "4. Subset Selction\n",
    "5. Apply Selected Features\n",
    "6. Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2559155e-533d-44bf-9533-33b1f50cd0aa",
   "metadata": {},
   "source": [
    "### 2 . How does the wrapper method differ from the filter method in feature selection ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c118eb7-fcc0-4e3e-ae00-d029a8ac0d65",
   "metadata": {},
   "source": [
    "- Difference between Wrapper and Filter method techniques are :\n",
    "|                   Wrapper                        |               Filter                            |\n",
    "|--------------------------------------------------|-------------------------------------------------|\n",
    "|1. Feature selection is treated as search problem where different subsets of features are evaluated by training models. |1. Feature selection is performed independetly of any machine learning algorithm. it relies on statistical properties of the data to select the most relevant feature|\n",
    "|2. it selects features based on performance of specific machine learning on different subsets |2. Features evaluated and selected based thier reelatioship with the target variable |\n",
    "|3. wrapper methods use specific models as black box to evaluate the quality of features subsets. |3. Filter methods do not involve building models, they apply statistical measures to rank score independently|\n",
    "|4. the evaluation od feature subsets is done using cross-validation|4. Filter methods are computationally efficient and can handle large datasets with many features|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb9b1f-971a-444f-ae61-57796b4d64be",
   "metadata": {},
   "source": [
    "### 3 . What are some common techniques used in Embedded feature selection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5825cf-b64d-45c1-96f5-4bfcb2803a97",
   "metadata": {},
   "source": [
    "##### Embedded feature selection methods integrate feature selection directly into the model building process. these methods automatically select the most relevant features as part of the model. \n",
    "\n",
    "- Some common techniques used in embedded feature selection methods :\n",
    "1. Lasso (Least Absolute Shrinkage and Selection Operator)\n",
    "2. Elastic Net\n",
    "3. Decision Trees(and Ensemble Methods like Random Forests and Gradient Boosting Machines)\n",
    "4. Feature Importance Scores\n",
    "5. Regularized Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f135a154-a05a-4110-85fd-ded3bcf74fc4",
   "metadata": {},
   "source": [
    "### 4 . What are some drawbacks of using the Filter method for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbe508-c8fe-482d-8ea2-7ceef6ce5ea5",
   "metadata": {},
   "source": [
    "###### While the Filter MEthod for feature selection offers simplicity and computational efficiency, it also comes with several drawbacks such as : \n",
    "\n",
    "- Drawbacks of using Filter methods\n",
    "1. Independent assumption - it evalues featueres independently of each other ignoring the interactions and dependencies.\n",
    "\n",
    "2. Limited Model Performance Improvement - since its ignoring the interactions between the features it may perform poorly.\n",
    "\n",
    "3. Selection Bias - it selects features based on statistical measure / criteria. this can lead to selection bias\n",
    "\n",
    "4. Sensitivity to feature scaling - if feature have different scales, thier correlation coefficient may not accurately reflect their relationship\n",
    "\n",
    "5. Limited to Univariate Analysis - most filter analyze features individually related to target varibale without considering the combined effect on target varibale. \n",
    "\n",
    "6. statis Feature selection - the feature selection process is done before the model training and it may not adopt to the changing data.\n",
    "\n",
    "7. Difficulty in handling data - filter methods may struggle with high dimensional or complex data where feature interactions are prevalent. in such cases wrapper or embedded are more suitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd973b-684e-4a3b-bd3b-9c3accd8deb9",
   "metadata": {},
   "source": [
    "### 5 . In which situations would you prefer using the Filter method over the Wrapper method for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fba68-f403-4171-bf0c-d9a6aafb89d5",
   "metadata": {},
   "source": [
    "##### The choice between using filter method nad wrapper method for feature selection depends on various factors such as the dataset characteristics,computational resources and specific goals of analysis.\n",
    "\n",
    "- Some situations where filter method is prefered over the wrapper method\n",
    "1. Large dataset - the computational cost of wrapper method is high when the dataset is large.\n",
    "\n",
    "2. Independence of features - filter method only evaluates features independently. if dataset has highly independent features or interaction are not crucial then filter metho is sufficient\n",
    "\n",
    "3. Preprocessing stage - filter methods are often used as preprocessing step to reduce the dimensionaity to later apply more complex compuatational methods\n",
    "\n",
    "4. Noise handling - wrapper methods might overfit the data during feature selection. filter methods can be safer choice if noise in feature data.\n",
    "\n",
    "5. Interpretability - filter methods typically provide a ranking or score for each feature based on some statisticla measure. this ranking can be easily interpretable and can provide insights into the importnace of individual features, which might be valuable in certain applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42b59d-53f5-4488-9c46-628722d70a4f",
   "metadata": {},
   "source": [
    "### 6 . In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559a1b8-0cc5-4cdf-ad11-e26bff064dbb",
   "metadata": {},
   "source": [
    "- To choose most pertinent attributes for the predictive model of customer churn using filter method would be :\n",
    "\n",
    "1. Understand the problems and gain clarity of what customer churn in telecom comapany meansand context for it. and how it impacts business objectives.\n",
    "\n",
    "2. Explore the dataset, analyze the dataset containing various features related to customer behaviour,demographics,usage,and interactions.\n",
    "\n",
    "3. Select relevent metrics, choose metrics to evaluate the relevance of features to the target varibale. common metrics used in filter methods include correlation coefficient,mutual information,chi-squared test.\n",
    "\n",
    "4. compute feature scores,calculate scores or ranking based on the selected metrics.\n",
    "\n",
    "5. set theshold, features exceeding threshold are considered pertinent and selected for inclusion in the predictive model. \n",
    "\n",
    "6. Feature selection, select features that meet or exceed predetermined threshold\n",
    "\n",
    "7. Validate the feature set using appropriate techniques such as cross-validation. ensure that model is generalized to unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189fc38b-cb15-4e94-a4d0-bd4819cd5dea",
   "metadata": {},
   "source": [
    "### 7 . You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365927d7-4f6d-4c4c-9c58-a15bc6d1a500",
   "metadata": {},
   "source": [
    "- In the context of predicting the outcome of a soccer match using embedded method for feature selection. within the process of model training. one of the most commonly used embedded regularization method is lasso(L1) and Ridge (L2 regularization). \n",
    "\n",
    "1. Data preprocessing : handling missing values,encoding,categorical variables and scaling numerical features if necessary. \n",
    "\n",
    "2. Feature engineering : Generate additional features that might be relevant for predicting soccer match outcomes. this could include aggregating player satistics over previous matches, history data,weather conditions.\n",
    "\n",
    "3. Model training with embedded methods \n",
    "- Lasso Regression (L1 Regularization) :\n",
    "1. Train a lasso regression model on dataset. it performs feature selection by penelizing absolute magnitube of the coefficients. it tends to shrink coefficients of less important features to zero. effectively performing feature selection.\n",
    "2. During training process the L1 regularization term encourages sparsity in coefficient vector. \n",
    "3. The coefficients of non-zero fatures in trained lasso model indicate thier importance in predicting match outcomes. \n",
    "\n",
    "- Ridge regression (L2 Regularization) :\n",
    "1. Alternatively you can also train ridge regression model which usee L2 regularization, while ridge regression does not perform feature selection as agressively as Lasso, it still penelizes large coeffients and can help mitigate multicollinearity issues.\n",
    "2. Ridge regression can be used in conjunction with techniques such as cross-validation to determine the optimal regularization parameter (alpha) that balances mdoel complexity and predictive performance.\n",
    "\n",
    "4. Feature selction and model evaluation \n",
    "- after training embedded models,extract the seelcted features based on non-zero coefficients obtained from models.\n",
    "- Evaluate the predictive performance of the selected features using appropriate metrics such as accuracy,precision and recall.employ cross-validation or holdout validation techniques to asses the generalizatoin of the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94823ec7-6b6e-471c-923b-456ded374ae6",
   "metadata": {},
   "source": [
    "### 8 . You are working on a project to predict the price of a house based on its features, such as size, location,and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af30b1-2da7-4f23-b0d7-7f7945e4d259",
   "metadata": {},
   "source": [
    "- to select best set of features for predicting the price of a house using the wrapper method, common wrapper method is recursive feature elimination (RFE).\n",
    "\n",
    "1. Define feature set, initial set of features that you want to consider for predicting house prices. this might include features such as size,location,age of property,number of bedroom/bathroom..etc\n",
    "\n",
    "2. choose a predicive model, that will be used for feature selection. common choices include linear regression,decision trees,random forest or gradient boosting models. \n",
    "\n",
    "3. Feature ranking with Recursive Feature Elimination (RFE):\n",
    "- initalization : train the chosen predictive model using initial set of features\n",
    "- Feature ranking : evaluate importance of each feature based on model's coefficient or feature importances\n",
    "- Feature elimination : Remove the least important features from the current set of features.\n",
    "- Model retraining : Retrain model using reduced feature set.\n",
    "- iteration : repeat from second step until predtermined number of features is reached.\n",
    "- Select optmal subset, that maximizes the model's performance on a validation seton cross validation. \n",
    "\n",
    "4. evaluate performance using metrics such as mean squared error (MSE) mean absolute error (MAR) R-squared .\n",
    "\n",
    "5. iterate and refine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8297a5e-d83d-4acf-9516-d66f0f643991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
